{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, Embedding, Dropout, Bidirectional, LSTM\n",
    "from keras.datasets import imdb\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer, text_to_word_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\keras\\datasets\\imdb.py:49: UserWarning: The `nb_words` argument in `load_data` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `load_data` '\n",
      "c:\\program files\\python36\\lib\\site-packages\\keras_preprocessing\\text.py:174: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1337)\n",
    "max_features = 25000\n",
    "maxlen = 200  # cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 64\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(nb_words=max_features)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128,input_length=maxlen))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=2500, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/7\n",
      "25000/25000 [==============================] - 2640s 106ms/step - loss: 0.3947 - acc: 0.8189 - val_loss: 0.3356 - val_acc: 0.8558\n",
      "Epoch 2/7\n",
      "25000/25000 [==============================] - 2610s 104ms/step - loss: 0.1999 - acc: 0.9261 - val_loss: 0.3378 - val_acc: 0.8650\n",
      "Epoch 3/7\n",
      "25000/25000 [==============================] - 2588s 104ms/step - loss: 0.1246 - acc: 0.9576 - val_loss: 0.3766 - val_acc: 0.8560\n",
      "Epoch 4/7\n",
      "25000/25000 [==============================] - 2029s 81ms/step - loss: 0.0812 - acc: 0.9726 - val_loss: 0.4705 - val_acc: 0.8483\n",
      "Epoch 5/7\n",
      "25000/25000 [==============================] - 13171s 527ms/step - loss: 0.0933 - acc: 0.9668 - val_loss: 0.4750 - val_acc: 0.8554\n",
      "Epoch 6/7\n",
      "25000/25000 [==============================] - 1622s 65ms/step - loss: 0.0459 - acc: 0.9856 - val_loss: 0.5396 - val_acc: 0.8462\n",
      "Epoch 7/7\n",
      "25000/25000 [==============================] - 1487s 59ms/step - loss: 0.0375 - acc: 0.9881 - val_loss: 0.5459 - val_acc: 0.8385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xe5f32631d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=7, validation_data=[X_test, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 147s 6ms/step\n",
      "loss: 0.5458828162193299\n",
      "acc: 0.83852\n",
      "saved model to disk\n"
     ]
    }
   ],
   "source": [
    "loss,accuracy = model.evaluate(X_test,y_test)\n",
    "print('loss:',loss)\n",
    "print('acc:',accuracy)\n",
    "\n",
    "#serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "#serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\keras_preprocessing\\text.py:174: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "#predicting for new datasets\n",
    "from keras.preprocessing import text\n",
    "from keras.models import model_from_json\n",
    "\n",
    "json_file = open('model.json','r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "#load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "\n",
    "#compile and evaluate loaded model\n",
    "loaded_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "tokenizer = Tokenizer(nb_words=2500, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textToNumeric(text):\n",
    "    #tokenizer.fit_on_texts(text)\n",
    "    numericText = tokenizer.texts_to_sequences(text)\n",
    "    paddedInput = sequence.pad_sequences(numericText,maxlen=maxlen)\n",
    "    \n",
    "    return paddedInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this has to be loaded for new text conversion into vectors\n",
    "word_index = imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hi', 'i', 'have', 'ordered', 'two', 'medium', 'pizza', 'and', 'two', 'numbers', 'of', 'chicken', 'wings', 'i', 'have', 'made', 'online', 'payment', 'through', 'my', 'debit', 'card', 'my', 'order', 'no', 'is', '232', 'dated', '27', '06', '2018', 'amounting', 'to', 'rs', '1432', 'payment', 'has', 'been', 'done', 'and', 'then', 'i', 'received', 'a', 'call', 'from', 'protected', 'telling', 'me', 'that', 'chicken', 'wings', 'are', 'out', 'of', 'stock', 'the', 'payment', 'for', 'the', 'same', 'will', 'be', 'send', 'back', 'in', '7', 'to', '8', 'days', 'the', 'main', 'issue', 'is', 'that', 'f', 'it', 'was', 'not', 'in', 'stock', 'then', 'why', 'it', 'was', 'not', 'displayed', 'now', 'after', 'payment', 'it', 'is', 'being', 'said', 'that', 'it', 'is', 'out', 'of', 'stock', 'will', 'you', 'let', 'me', 'know', 'how', 'would', 'you', 'compensate', 'for', 'my', 'grievance', 'all', 'my', 'friends', 'and', 'me', 'are', 'totally', 'frustrated']\n"
     ]
    }
   ],
   "source": [
    "# define the document\n",
    "doc1 = \"Hi I have ordered two medium pizza and two numbers of chicken wings. I have made online payment through my debit card. My order No. is 232 dated 27.06.2018 amounting to Rs. 1432. Payment has been done and then I received a call from protected telling me that chicken wings are out of stock. The payment for the same will be send back in 7 to 8 days.The main issue is that f it was not in stock then why it was not displayed. Now after payment it is being said that it is out of stock. Will you let me know how would you compensate for my grievance all My friends and Me are totally frustrated\"\n",
    "# tokenize the document\n",
    "tokenizedText= text_to_word_sequence(doc1)\n",
    "print(tokenizedText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6593,    10,    25,  5172,   104,  3446,  7754,     2,   104,\n",
       "        1393,     4,  5142,  5831,    10,    25,    90,  4689, 11334,\n",
       "         140,    58,     0,  3152,    58,   658,    54,     6,     0,\n",
       "        1964,  7508, 19839,     0,     0,     5,     0,     0, 11334,\n",
       "          44,    74,   221,     2,    92,    10,  1987,     3,   680,\n",
       "          36, 14844,   976,    69,    12,  5142,  5831,    23,    43,\n",
       "           4,  2050,     1, 11334,    15,     1,   169,    77,    27,\n",
       "        2219,   142,     8,   690,     5,   706,   501,     1,   290,\n",
       "        1831,     6,    12,  1206,     9,    13,    21,     8,  2050,\n",
       "          92,   135,     9,    13,    21,  4339,   147,   100, 11334,\n",
       "           9,     6,   109,   298,    12,     9,     6,    43,     4,\n",
       "        2050,    77,    22,   384,    69,   121,    86,    59,    22,\n",
       "        7965,    15,    58,     0,    29,    58,   366,     2,    69,\n",
       "          23,   481,  3568])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericText = np.array([word_index[word] if (word in word_index) and (word_index[word]<25000) else 0 for word in tokenizedText])\n",
    "numericText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,  6593,\n",
       "           10,    25,  5172,   104,  3446,  7754,     2,   104,  1393,\n",
       "            4,  5142,  5831,    10,    25,    90,  4689, 11334,   140,\n",
       "           58,     0,  3152,    58,   658,    54,     6,     0,  1964,\n",
       "         7508, 19839,     0,     0,     5,     0,     0, 11334,    44,\n",
       "           74,   221,     2,    92,    10,  1987,     3,   680,    36,\n",
       "        14844,   976,    69,    12,  5142,  5831,    23,    43,     4,\n",
       "         2050,     1, 11334,    15,     1,   169,    77,    27,  2219,\n",
       "          142,     8,   690,     5,   706,   501,     1,   290,  1831,\n",
       "            6,    12,  1206,     9,    13,    21,     8,  2050,    92,\n",
       "          135,     9,    13,    21,  4339,   147,   100, 11334,     9,\n",
       "            6,   109,   298,    12,     9,     6,    43,     4,  2050,\n",
       "           77,    22,   384,    69,   121,    86,    59,    22,  7965,\n",
       "           15,    58,     0,    29,    58,   366,     2,    69,    23,\n",
       "          481,  3568]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_inp = sequence.pad_sequences([numericText],maxlen=maxlen)\n",
    "numeric_inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9746414]]\n"
     ]
    }
   ],
   "source": [
    "out = loaded_model.predict(numeric_inp)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(text):\n",
    "    tokenizedText= text_to_word_sequence(text)\n",
    "    numericText = np.array([word_index[word] if (word in word_index) and (word_index[word]<25000) else 0 for word in tokenizedText])\n",
    "    numeric_inp = sequence.pad_sequences([numericText],maxlen=maxlen)\n",
    "    out = loaded_model.predict(numeric_inp)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9746414]]\n"
     ]
    }
   ],
   "source": [
    "doc2 = \"Hi I have ordered two medium pizza and two numbers of chicken wings. I have made online payment through my debit card. My order No. is 232 dated 27.06.2018 amounting to Rs. 1432. Payment has been done and then I received a call from protected telling me that chicken wings are out of stock. The payment for the same will be send back in 7 to 8 days.The main issue is that f it was not in stock then why it was not displayed. Now after payment it is being said that it is out of stock. Will you let me know how would you compensate for my grievance all My friends and Me are totally frustrated\"\n",
    "print(sentiment(doc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.87709075]]\n"
     ]
    }
   ],
   "source": [
    "print(sentiment(\"i like it\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
